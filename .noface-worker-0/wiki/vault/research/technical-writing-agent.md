# AI-Generated Technical Documentation: Quality Challenges and Improvement Strategies

> Research summary on LLM documentation quality and multi-agent improvement strategies

See also: [[design/doc-agent]]

## LLM-Generated Documentation Quality in Research

Recent research highlights significant issues with documentation
produced by large language models. Studies have found that LLM-generated
docs often omit important details (for example, missing parameter or
return descriptions), provide minimal contextual explanation, or even
include fabricated information that doesn’t match the
code[\[1\]](https://arxiv.org/html/2504.08725v1#:~:text=Zhang%20et%C2%A0al,2024).
In other words, these models can be **verbose without clarity** and
sometimes **factually unreliable**. Practitioners echo these concerns:
one discussion noted that LLMs tend to produce *“waffly, unreliable
garbage”* if left unchecked, which is the opposite of the concise
accuracy good documentation
needs[\[2\]](https://www.reddit.com/r/AskProgramming/comments/1j1n51j/why_cant_we_have_llms_writing_documentation/#:~:text=,writing%20documentation).
Overall, the consensus is that out-of-the-box LLM writing may sound
fluent, but it **lags behind human-written docs in precision and
usefulness** unless carefully guided or improved.

Researchers are actively measuring this quality gap. For instance, one
2025 study evaluated tech content generated by multiple LLMs (with
retrieval augmentation) against human
standards[\[3\]](https://aclanthology.org/2025.nodalida-1.67/#:~:text=Large%20language%20models%20,a%20Network%20Analysis%20and%20linear)[\[4\]](https://aclanthology.org/2025.nodalida-1.67/#:~:text=and%20the%20distribution%20of%20human,when%20using%20different%20analysis%20frameworks).
It found that traditional metrics (like BLEU/ROUGE) don’t fully capture
quality, and that human evaluators cared more about factual correctness
and
coherence[\[5\]](https://aclanthology.org/2025.nodalida-1.67/#:~:text=LLM,when%20using%20different%20analysis%20frameworks).
Another team at Meta introduced a system called **DocAgent** to address
LLM shortcomings. They note that typical LLM-based approaches produce
*“incomplete, unhelpful, or factually incorrect
outputs”*[\[6\]](https://arxiv.org/html/2504.08725v1#:~:text=High,Comprehensive%20experiments%20show%20DocAgent),
and specifically tend to skip essential info, lack rationale, or
hallucinate nonexistent
components[\[1\]](https://arxiv.org/html/2504.08725v1#:~:text=Zhang%20et%C2%A0al,2024).
These issues motivated DocAgent’s design – a specialized multi-agent
pipeline – which *“significantly outperforms”* standard LLM baselines on
documentation
tasks[\[7\]](https://arxiv.org/html/2504.08725v1#:~:text=Models%20,Our%20ablation%20study%20confirms).
The takeaway from research is clear: **vanilla LLMs struggle with
high-quality documentation**, but structured improvements can narrow the
gap.

## Techniques for More Concise and Accurate AI Writing

To make LLMs write **less, but better**, several strategies are being
explored. The goal is to enforce the *clarity, brevity, and correctness*
that human technical writers strive for:

- **Critic-Writer Loops:** Instead of one-pass generation, the AI can
  iteratively refine the text through a two-agent loop. A *Writer* agent
  drafts the documentation, then a *Critic* agent reviews it and
  suggests edits or flags problems (e.g. unnecessary fluff, unclear
  parts, or inaccuracies). This process repeats for a few cycles. Such
  critic–writer or self-refinement loops have shown improved output
  quality in
  practice[\[8\]](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/#:~:text=,draft%2C%20identifying%20areas%20for%20improvement).
  For example, Google’s ADK toolkit demonstrates a loop agent that runs
  a writer and a critic in sequence, stopping when the document is “good
  enough”[\[8\]](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/#:~:text=,draft%2C%20identifying%20areas%20for%20improvement).
  Academic results confirm that a critique-and-revision approach can
  reduce errors like hallucinations and keep the text on track after a
  few
  iterations[\[9\]](https://arxiv.org/html/2510.24469v1#:~:text=through%20iterative%20refinement%2C%20inspired%20by,dimensions%20of%20personalized%20text%20generation)[\[10\]](https://arxiv.org/html/2510.24469v1#:~:text=Our%20results%20show%20consistent%20gains,variant%20balances%20performance%20and%20efficiency).
  In essence, the critic forces the writer to **trim filler, fix
  ambiguity, and focus on accuracy** in each round. This can help reign
  in the overly verbose, “helpfulness”-optimized style of raw LLM
  outputs.

- **Reader State Modeling:** A known weakness of LLM prose is losing
  track of what the *reader* already knows. Techniques here aim to
  explicitly model the reader’s knowledge or context and tailor the
  writing accordingly. In practical terms, this means the AI should
  avoid explaining or restating concepts the target audience would find
  obvious, while **not omitting prerequisites** that a newcomer might
  need. One approach is to include an outline of the reader’s assumed
  background in the prompt (e.g. “Assume the reader is an intermediate
  Python developer familiar with X library but not Y concept”). By
  keeping a running “reader model,” the documentation agent can decide
  which details to elaborate and which to skip. This idea aligns with
  advice from professional writers: good documentation *“considers who
  the reader might be or what they
  want”*[\[11\]](https://news.ycombinator.com/item?id=35759449#:~:text=HOWEVER,get%20out%20of%20the%20writing).
  When writers don’t do this, you get the notorious “just simply…”
  problem – filler phrases that **add nothing and often misjudge the
  audience’s
  needs**[\[12\]](https://news.ycombinator.com/item?id=35759449#:~:text=The%20main%20problems%20with%20the,writing%20are%20twofold).
  In practice, few-shot prompts or chain-of-thought might be used to
  have the LLM reason about “What does the reader already know?” before
  writing each section. This is an active area of experimentation, but
  the guiding principle is to **write with the reader’s perspective in
  mind**, resulting in more focused, relevant docs (and a lot less
  rambling).

- **Diff-Based Documentation:** Rather than generating docs from
  scratch, the agent can limit its scope to *just the changes or new
  features* in the code. This “diff-based” approach treats documentation
  as an incremental update: for example, after a code review passes, the
  agent looks at the git diff or the list of issues closed and **writes
  only about those changes**. By describing *what changed and why*, it
  inherently produces concise content (since it avoids rehashing
  unchanged parts of the system). Research backs the feasibility of this
  approach – tools have been developed to summarize code differences in
  plain language. Notably, Buse & Weimer (2010) presented a technique to
  synthesize *“succinct human-readable documentation for arbitrary
  program differences,”* automating what is essentially a descriptive
  commit
  message[\[13\]](https://scispace.com/papers/towards-automatic-generation-of-short-summaries-of-commits-5qyskbjfhe?references_page=2#:~:text=TL%3BDR%3A%20An%20automatic%20technique%20for,directly%20describe%20a%20code%20change).
  They found such generated summaries could supplement or replace a high
  percentage of human-written change
  logs[\[13\]](https://scispace.com/papers/towards-automatic-generation-of-short-summaries-of-commits-5qyskbjfhe?references_page=2#:~:text=TL%3BDR%3A%20An%20automatic%20technique%20for,directly%20describe%20a%20code%20change).
  In a modern context, an LLM agent could detect that a new API endpoint
  was added and draft an **API change note** or update relevant
  reference docs for that endpoint, while leaving the rest of the
  documentation untouched. This ensures brevity and relevance. It also
  aligns with how maintainers often write release notes: focusing only
  on what’s new or changed. A diff-based doc agent would integrate with
  version control, triggering when certain labels (like “docs needed”)
  appear in the commit or PR metadata. By scoping the task to diffs, we
  avoid the LLM’s tendency to regurgitate entire sections or introduce
  unrelated info.

- **Example-First Writing:** Many developers learn best from examples,
  so an emerging strategy is to have the AI documentation emphasize code
  examples *before* lengthy explanations. In this approach, the agent
  might output a minimal working code snippet or usage example for a new
  feature **first**, then follow up with a brief explanatory text. This
  flips the usual narrative-heavy style: the example demonstrates the
  feature in context, and the prose only clarifies points that the
  example alone wouldn’t convey. The effect is higher information
  density and less filler. For instance, instead of a verbose paragraph
  describing an API call, an example-first doc would show a short code
  sample of that API in use, and perhaps one or two sentences
  highlighting key aspects of the example. Users get a quick
  understanding without wading through exposition. Some LLM-driven
  systems already incorporate this. A recent blog noted that companies
  like Stripe and Twilio use AI pipelines to keep API docs up-to-date –
  they **extract code and comments, then have the LLM generate
  descriptions *plus usage examples***
  automatically[\[14\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=With%20an%20LLM%20pipeline%3A)[\[15\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=,Markdown%2C%20PDF%2C%20or%20Confluence%20pages).
  By letting examples carry much of the weight, the documentation agent
  naturally writes less fluff. Additionally, examples serve as an
  accuracy check: it’s easier to spot if the AI produces a wrong code
  example (which can then be corrected by tests or a review) than to
  catch a subtle error buried in prose. Example-first documentation thus
  helps maintain correctness and conciseness. It ties into the idea of
  showing rather than telling – a well-chosen snippet can often replace
  a paragraph of explanation.

- **Structured Templates and Sections:** Enforcing a consistent
  structure on the documentation can greatly reduce meandering text. The
  agent is guided to fill in specific fields or sections, much like a
  form, rather than writing an open-ended essay. For instance, an **API
  reference entry** might have a fixed template: *“Function: … –
  Description: … – Parameters: … – Returns: … – Example: … – Notes: …”*.
  By giving the LLM this scaffold, we compel it to stay on topic and
  complete each required piece of info. This not only cuts down
  unnecessary verbiage but also ensures completeness (each important
  item is addressed explicitly). Similarly, for a **tutorial or
  conceptual article**, a template might dictate an introduction, a
  setup section, a series of steps each with a code sample, and a
  conclusion. Sticking to a template combats the LLM’s tendency to drift
  or add superfluous paragraphs. In practice, designing these prompts
  and formats can be an iterative process. The Datadog engineering team,
  for example, spent over 100 hours refining prompt structure and
  section instructions for their post-mortem report
  generator[\[16\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=iterating%20on%20the%20structure%20and,part%20of%20a%20hardwired%20feature).
  They found that tightly structuring the output (and tuning each
  section’s prompt) helped the LLM maintain consistent formatting, avoid
  repetition, and reduced hallucinations in a “hardwired”
  setting[\[16\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=iterating%20on%20the%20structure%20and,part%20of%20a%20hardwired%20feature).
  Essentially, template-driven generation acts as **guardrails**,
  focusing the AI on *what needs to be said* and nothing more. Another
  benefit is consistency across documentation: every page follows a
  known format, which users appreciate. Many documentation systems (like
  Javadoc, Sphinx, or Divio’s framework) rely on structured layouts for
  clarity; an AI agent can be instructed to output in those formats too.
  By forcing, say, **separate sections for “Concept” vs “How-To”**, we
  prevent an LLM from mixing conceptual background into a step-by-step
  guide or vice versa. Overall, structured templates are a powerful way
  to make LLM documentation more like a fill-in-the-blanks exercise –
  reducing irrelevant verbosity and keeping the content precise.

In combination, these techniques aim to **rein in the verbosity and
unpredictability** of LLMs. Critic loops add a feedback mechanism to cut
fluff; reader modeling and templates anchor the content to what’s
necessary for the audience; diff-based and example-centric approaches
limit the scope and encourage “show, don’t tell” brevity. Early
experiments are promising: for instance, using retrieval-augmented
generation (RAG) with an LLM is another method to maintain accuracy and
brevity – by pulling in only relevant code/context, the model is less
likely to speculate or over-explain. One practitioner suggests using RAG
so the documentation *“is factually tied to your codebase and internal
data”*[\[17\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=,docs%20still%20need%20human%20review),
rather than the model’s general training. All these approaches share a
common theme: **constrain and guide the LLM** so that it outputs
**concise, correct, and audience-targeted documentation** instead of
chatty, generic text.

## How Professional Tech Writers Handle Information Density

Professional technical writers are keenly aware that **less is more**
when it comes to documentation. They strive for high *information
density* – every sentence should serve a purpose. Filler phrases and
fluff are ruthlessly edited out, because they add cognitive overhead for
readers without adding value. In fact, most official style guides
explicitly warn against using words like “just”, “simply”, “of course”,
or other softeners that writers (and LLMs) often
overuse[\[18\]](https://news.ycombinator.com/item?id=35759449#:~:text=Technical%20writer%20checking%20in%20to,speak).
As one technical writer quipped: *“Don’t hype up how easy it is… just
tell us how to install the
thing!”*[\[18\]](https://news.ycombinator.com/item?id=35759449#:~:text=Technical%20writer%20checking%20in%20to,speak).
The rationale is twofold: first, **unnecessary words make docs harder to
scan and understand**, especially if a reader is skimming for a
solution. Extra verbiage forces the reader to parse and then discard
those
words[\[12\]](https://news.ycombinator.com/item?id=35759449#:~:text=The%20main%20problems%20with%20the,writing%20are%20twofold).
And second, a casual, assumptive tone (e.g. “simply do X…”) can come off
as condescending or misleading – what’s “simple” to the author might not
be simple to the
user[\[19\]](https://news.ycombinator.com/item?id=35759449#:~:text=2,same%20level%20as%20the%20author).
This ties back to knowing the audience: good tech writers avoid implying
the user is ignorant or lazy; instead they neutrally present the steps
or facts.

In practice, professional documentation is **written in a
straightforward, instructional style**. Writers favor clear
subject–verb–object sentences in active voice, and they avoid padding.
For example, rather than saying “It is very easy to quickly set up the
configuration by basically following these simple steps…”, a well-edited
doc would say “**To configure the system, follow these steps:**” and
then list them. Every word that doesn’t *help* the reader is seen as a
cost. As a comment on Hacker News summarized: *“Good writing is stripped
of superfluous filler words… save the flowery prose for your
poetry”*[\[12\]](https://news.ycombinator.com/item?id=35759449#:~:text=The%20main%20problems%20with%20the,writing%20are%20twofold).
Professionals also structure information so that critical details aren’t
buried. They use headings, bullet points, tables, and visuals to
communicate efficiently. Dense blocks of text are anathema in technical
docs – if something can be said in a few words or shown in a diagram, it
will be. Information density isn’t about cramming in more text; it’s
about **maximizing insight per line**. This philosophy is something we
want to impart to LLM-based documentation agents as well. By applying
style rules (perhaps through a critic agent or fine-tuning on technical
writing samples), we can push AI outputs closer to this human ideal:
**concise, precise, and respectful of the reader’s time**.

It’s worth noting that human writers also consider *what not to say*.
They don’t explain obvious prerequisites to an expert audience, and they
don’t repeat the same info in multiple places needlessly. They assume a
reasonable baseline knowledge (or clearly state prerequisites at the
start) and then focus on new or tricky concepts. This is related to the
earlier point about reader modeling. The human practice is to *omit
needless words* (as Strunk & White would say) and also needless
explanations. For an AI documentation system, imitating this means
dynamically adjusting the level of detail: if documenting a low-level
API for experienced developers, it should be terse and get straight to
the point; if writing a beginner tutorial, it can be more verbose but
still **purposeful**. The common denominator is not wasting the reader’s
attention. As professionals would agree, **documentation succeeds when
it delivers the required information in the most direct way possible**.

## Examples of Successful LLM-Based Documentation Pipelines

Several organizations and projects have started to crack the code on
AI-assisted documentation, building pipelines that show promising
results:

- **Meta’s DocAgent (2024):** Mentioned earlier, DocAgent is a
  multi-agent system developed by Meta AI researchers to automate code
  documentation. It uses a *Reader* agent to gather code context, a
  *Searcher* to pull in relevant external info if needed, a *Writer* to
  draft the docstring or API comment, and a *Verifier* to double-check
  correctness, all coordinated by an
  Orchestrator[\[7\]](https://arxiv.org/html/2504.08725v1#:~:text=Models%20,Our%20ablation%20study%20confirms)[\[20\]](https://arxiv.org/html/2504.08725v1#:~:text=novel%20multi,Will%20update).
  Importantly, DocAgent processes a codebase in a logical order (using a
  dependency graph) so that each piece of documentation is generated
  with proper
  context[\[21\]](https://arxiv.org/html/2504.08725v1#:~:text=Image%3A%20Refer%20to%20caption%20Figure,aware%20documentation%20generation)[\[22\]](https://arxiv.org/html/2504.08725v1#:~:text=To%20tackle%20these%20challenges%2C%20we,measuring%20completeness%2C%20helpfulness%2C%20and%20factual).
  In evaluations, this sophisticated pipeline **outperformed baseline
  single-LLM approaches** on metrics of completeness, helpfulness, and
  factual
  accuracy[\[23\]](https://arxiv.org/html/2504.08725v1#:~:text=Verifier%2C%20Orchestrator,2%7D2https%3A%2F%2Fyoutu.be%2Fe9IjObGe9_I%20are%20publicly%20available)[\[1\]](https://arxiv.org/html/2504.08725v1#:~:text=Zhang%20et%C2%A0al,2024).
  In other words, by breaking the task into specialized roles and
  ordering, they achieved higher quality docs than a one-shot GPT-4
  doing everything. DocAgent demonstrates a successful orchestration: it
  addresses the omissions and hallucinations by ensuring each agent has
  a focused job (and the verifier catches mistakes). This is a concrete
  example of an LLM-based documentation pipeline that is *modular* and
  *robust*, and it’s likely to inspire similar architectures in
  industry.

- **Databricks’ AI-Generated Docs (2023):** Databricks introduced an
  **AI documentation feature** for their Unity Catalog, which
  automatically generates descriptions for data tables and
  columns[\[24\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=We%20recently%20announced%20our%20AI,assisted).
  Their initial prototype used a third-party SaaS LLM, but they
  encountered issues with output quality and consistency (the model
  sometimes gave good suggestions, other times not, and even regressed
  as the provider updated the
  model)[\[25\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=1,It%20would)[\[26\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=generated%20documentation,affected%20performance%20on%20specific%20tasks).
  To gain more control, Databricks built their own fine-tuned model for
  this
  task[\[27\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=Building%20a%20bespoke%20model).
  In just a month, two engineers fine-tuned a smaller open-source LLM
  (MPT-7B) on a custom dataset of table schemas and high-quality sample
  descriptions[\[28\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=To%20address%20the%20aforementioned%20challenges%2C,was%20better%2C%20faster%2C%20and%20cheaper)[\[29\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=We%20created%20the%20initial%20training,two%20different%20sources%20of%20data).
  The result was a bespoke model that produced *better documentation
  quality* than the cheaper tier of the SaaS model and nearly matched
  the expensive tier, all at a fraction of the
  cost[\[30\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=,fold%20reduction%20in%20inference%20cost).
  By evaluating how often users accepted the AI suggestions, they saw
  significant improvement in acceptance
  rates[\[31\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=,a%20few%20dollars%2C%20and%20in).
  In production, over 80% of table metadata updates were AI-assisted,
  showing that users found the suggestions
  useful[\[24\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=We%20recently%20announced%20our%20AI,assisted).
  This pipeline is successful due to domain-specific tuning and
  continuous evaluation. They also implemented an evaluation workflow
  (with human raters doing blind comparisons between the AI and baseline
  outputs) to ensure the model met quality bars before
  deployment[\[32\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=of%20the%20SaaS%20LLM)[\[33\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=Model%20selection%20and%20fine).
  Databricks’ experience suggests that **fine-tuning an LLM on real
  documentation examples and controlling the prompt format can yield
  high-quality, precise docs** in a specific domain. It also underlines
  the value of monitoring – they treat it as an ongoing iterative
  process, retraining and improving the model as
  needed[\[34\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=The%20first%20step%20was%20to,was%20that%20we%20needed%20to)[\[35\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=We%20considered%20the%20following%20criteria,for%20model%20selection).

- **Datadog’s Postmortem Assistant (2024):** Datadog built a feature (as
  part of their “Bits AI” tools) to help engineers draft incident
  postmortems using
  LLMs[\[36\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=Writing%20a%20postmortem%20is%20an,the%20details%20of%20the%20incident)[\[37\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=make%20this%20process%20easier%2C%20we,the%20details%20of%20the%20incident).
  Their pipeline combines structured data (incident metadata from their
  management system) with unstructured data (Slack discussion logs) as
  input[\[38\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=learning%20sre,the%20details%20of%20the%20incident)[\[39\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=To%20implement%20this%20solution%2C%20we,human%20authors%20to%20build%20upon).
  An ensemble of LLMs then produces a first-draft postmortem report for
  the human to
  refine[\[38\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=learning%20sre,the%20details%20of%20the%20incident).
  What’s notable is how much effort they put into template design and
  feedback loops. They broke the postmortem into sections (Summary,
  Impact, Root Cause, etc.) and crafted prompts for each, testing and
  tweaking
  repeatedly[\[40\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=efforts%20that%20go%20beyond%20commonly,part%20of%20a%20hardwired%20feature).
  Over months, they fine-tuned these instructions to get outputs that
  were consistent in format and high in factual
  accuracy[\[16\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=iterating%20on%20the%20structure%20and,part%20of%20a%20hardwired%20feature).
  They also had to address classic LLM problems: the model sometimes
  ignored instructions, repeated itself, or produced false
  information[\[16\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=iterating%20on%20the%20structure%20and,part%20of%20a%20hardwired%20feature).
  By iterating on the prompt structure and adding validation steps (like
  checking the draft against known incident data), they managed to
  mitigate these issues. The end result is a pipeline that saves
  engineers time by providing a solid starting draft for incident
  reports, while keeping engineers in control to do the final
  edits[\[36\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=Writing%20a%20postmortem%20is%20an,the%20details%20of%20the%20incident)[\[41\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=large%20language%20models%20,the%20details%20of%20the%20incident).
  This human-in-the-loop design is a common theme in successful
  pipelines – the AI does the heavy lifting of synthesizing info, but a
  human author ensures the nuances and tone are right. Datadog reports
  that the solution sped up documentation without compromising the
  quality and learning value of the postmortem
  process[\[36\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=Writing%20a%20postmortem%20is%20an,the%20details%20of%20the%20incident)[\[42\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=We%20learned%20that%20you%20can%E2%80%99t,we%20unearthed%20during%20this%20project).
  Their experience highlights the importance of **section templates and
  rigorous prompt tuning** in an LLM doc system.

- **Other Notable Examples:** Several other companies have rolled out
  AI-assisted documentation tools. The Medium example we saw mentioned
  Stripe and Twilio using LLMs to keep API reference docs current in
  “near
  real-time”[\[15\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=,Markdown%2C%20PDF%2C%20or%20Confluence%20pages).
  While details are sparse, this likely involves integrating an LLM with
  their build or CI pipeline: when new API endpoints or parameters are
  added, the system generates or updates the relevant reference pages
  immediately. This is essentially “docs as code” but with an AI helping
  to draft the text. Another example is **Notion’s** AI features, which
  can generate user-facing documentation and even translate it to other
  languages
  instantly[\[43\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=documentation).
  On the open-source side, there’s experimental work on using GPT-based
  bots to generate docstrings or README content for GitHub projects. And
  of course, Microsoft’s documentation team has explored using GPT-4 for
  summarizing conceptual docs or suggesting improvements to MSDN/Docs
  content (with human review in the loop). Many of these efforts are not
  fully public, but the common thread is **LLM pipelines augmenting, not
  replacing, human writers**. They serve as draft generators or editors,
  which is where they excel, while humans approve and polish the final
  output.

In summary, successful LLM documentation pipelines tend to incorporate
**several best practices**: they break the task into smaller pieces
(often with multiple prompts or agents), they use domain-specific data
or fine-tuning to ground the model, they enforce structure/templates to
maintain consistency, and they include human oversight for validation.
By doing so, they overcome the baseline issues of verbosity and
inaccuracy. As we integrate a documentation agent into our own
orchestration system, these examples provide a roadmap. We’ll want to
leverage diffs and code context to focus the AI, perhaps use a critic
loop to refine drafts, and definitely define clear templates for the
types of docs we need (API ref, conceptual guide, tutorial). With
careful design and iteration, an LLM-based agent can indeed produce
**high-quality technical writing** – not by mimicking the verbose
“helpful” style, but by adhering to the disciplined, reader-focused
approach that human tech writers have
perfected[\[18\]](https://news.ycombinator.com/item?id=35759449#:~:text=Technical%20writer%20checking%20in%20to,speak).
The research and real-world cases show that this is achievable, and it
can dramatically reduce the mundane burden of writing while **keeping
documentation accurate, concise, and
up-to-date**[\[44\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=,docs%20still%20need%20human%20review)[\[45\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=We%E2%80%99re%20moving%20towards%20%E2%80%9Cdocs%20as,code%20%2B%20AI%E2%80%9D).

**Sources:** The insights above draw from a mix of recent research
papers, industry case studies, and professional writing guidelines. Key
references include Meta’s *DocAgent* paper on multi-agent doc
generation[\[7\]](https://arxiv.org/html/2504.08725v1#:~:text=Models%20,Our%20ablation%20study%20confirms)[\[1\]](https://arxiv.org/html/2504.08725v1#:~:text=Zhang%20et%C2%A0al,2024),
the Databricks engineering blog on their AI documentation
model[\[46\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=,we%20did%20a%20lot%20of),
Datadog’s account of building an LLM-driven postmortem
tool[\[16\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=iterating%20on%20the%20structure%20and,part%20of%20a%20hardwired%20feature),
and commentary from seasoned technical writers on eliminating fluff in
docs[\[12\]](https://news.ycombinator.com/item?id=35759449#:~:text=The%20main%20problems%20with%20the,writing%20are%20twofold)[\[18\]](https://news.ycombinator.com/item?id=35759449#:~:text=Technical%20writer%20checking%20in%20to,speak).
These and other sources have been cited in context throughout the answer
for further reading and verification.

------------------------------------------------------------------------

[\[1\]](https://arxiv.org/html/2504.08725v1#:~:text=Zhang%20et%C2%A0al,2024)
[\[6\]](https://arxiv.org/html/2504.08725v1#:~:text=High,Comprehensive%20experiments%20show%20DocAgent)
[\[7\]](https://arxiv.org/html/2504.08725v1#:~:text=Models%20,Our%20ablation%20study%20confirms)
[\[20\]](https://arxiv.org/html/2504.08725v1#:~:text=novel%20multi,Will%20update)
[\[21\]](https://arxiv.org/html/2504.08725v1#:~:text=Image%3A%20Refer%20to%20caption%20Figure,aware%20documentation%20generation)
[\[22\]](https://arxiv.org/html/2504.08725v1#:~:text=To%20tackle%20these%20challenges%2C%20we,measuring%20completeness%2C%20helpfulness%2C%20and%20factual)
[\[23\]](https://arxiv.org/html/2504.08725v1#:~:text=Verifier%2C%20Orchestrator,2%7D2https%3A%2F%2Fyoutu.be%2Fe9IjObGe9_I%20are%20publicly%20available)
DocAgent: A Multi-Agent System for Automated Code Documentation
Generation

<https://arxiv.org/html/2504.08725v1>

[\[2\]](https://www.reddit.com/r/AskProgramming/comments/1j1n51j/why_cant_we_have_llms_writing_documentation/#:~:text=,writing%20documentation)
why can't we have LLMs writing documentation? : r/AskProgramming

<https://www.reddit.com/r/AskProgramming/comments/1j1n51j/why_cant_we_have_llms_writing_documentation/>

[\[3\]](https://aclanthology.org/2025.nodalida-1.67/#:~:text=Large%20language%20models%20,a%20Network%20Analysis%20and%20linear)
[\[4\]](https://aclanthology.org/2025.nodalida-1.67/#:~:text=and%20the%20distribution%20of%20human,when%20using%20different%20analysis%20frameworks)
[\[5\]](https://aclanthology.org/2025.nodalida-1.67/#:~:text=LLM,when%20using%20different%20analysis%20frameworks)
Generative AI for Technical Writing: Comparing Human and LLM Assessments
of Generated Content - ACL Anthology

<https://aclanthology.org/2025.nodalida-1.67/>

[\[8\]](https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/#:~:text=,draft%2C%20identifying%20areas%20for%20improvement)
Loop agents - Agent Development Kit

<https://google.github.io/adk-docs/agents/workflow-agents/loop-agents/>

[\[9\]](https://arxiv.org/html/2510.24469v1#:~:text=through%20iterative%20refinement%2C%20inspired%20by,dimensions%20of%20personalized%20text%20generation)
[\[10\]](https://arxiv.org/html/2510.24469v1#:~:text=Our%20results%20show%20consistent%20gains,variant%20balances%20performance%20and%20efficiency)
Iterative Critique-Refine Framework for Enhancing LLM Personalization

<https://arxiv.org/html/2510.24469v1>

[\[11\]](https://news.ycombinator.com/item?id=35759449#:~:text=HOWEVER,get%20out%20of%20the%20writing)
[\[12\]](https://news.ycombinator.com/item?id=35759449#:~:text=The%20main%20problems%20with%20the,writing%20are%20twofold)
[\[18\]](https://news.ycombinator.com/item?id=35759449#:~:text=Technical%20writer%20checking%20in%20to,speak)
[\[19\]](https://news.ycombinator.com/item?id=35759449#:~:text=2,same%20level%20as%20the%20author)
Just Simply – Stop saying how simple things are in our docs \| Hacker
News

<https://news.ycombinator.com/item?id=35759449>

[\[13\]](https://scispace.com/papers/towards-automatic-generation-of-short-summaries-of-commits-5qyskbjfhe?references_page=2#:~:text=TL%3BDR%3A%20An%20automatic%20technique%20for,directly%20describe%20a%20code%20change)
(Open Access) Towards automatic generation of short summaries of commits
(2017) \| Siyuan Jiang \| 49 Citations

<https://scispace.com/papers/towards-automatic-generation-of-short-summaries-of-commits-5qyskbjfhe?references_page=2>

[\[14\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=With%20an%20LLM%20pipeline%3A)
[\[15\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=,Markdown%2C%20PDF%2C%20or%20Confluence%20pages)
[\[17\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=,docs%20still%20need%20human%20review)
[\[43\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=documentation)
[\[44\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=,docs%20still%20need%20human%20review)
[\[45\]](https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65#:~:text=We%E2%80%99re%20moving%20towards%20%E2%80%9Cdocs%20as,code%20%2B%20AI%E2%80%9D)
LLM in Real World: Automating Documentation with LLMs \| by Gustavo
Bergamo \| Medium

<https://medium.com/@bergamo.gustavo/llm-in-real-world-automating-documentation-with-llms-6589595eee65>

[\[16\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=iterating%20on%20the%20structure%20and,part%20of%20a%20hardwired%20feature)
[\[36\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=Writing%20a%20postmortem%20is%20an,the%20details%20of%20the%20incident)
[\[37\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=make%20this%20process%20easier%2C%20we,the%20details%20of%20the%20incident)
[\[38\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=learning%20sre,the%20details%20of%20the%20incident)
[\[39\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=To%20implement%20this%20solution%2C%20we,human%20authors%20to%20build%20upon)
[\[40\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=efforts%20that%20go%20beyond%20commonly,part%20of%20a%20hardwired%20feature)
[\[41\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=large%20language%20models%20,the%20details%20of%20the%20incident)
[\[42\]](https://www.datadoghq.com/blog/engineering/llms-for-postmortems/#:~:text=We%20learned%20that%20you%20can%E2%80%99t,we%20unearthed%20during%20this%20project)
How we optimized LLM use for cost, quality, and safety to facilitate
writing postmortems \| Datadog

<https://www.datadoghq.com/blog/engineering/llms-for-postmortems/>

[\[24\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=We%20recently%20announced%20our%20AI,assisted)
[\[25\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=1,It%20would)
[\[26\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=generated%20documentation,affected%20performance%20on%20specific%20tasks)
[\[27\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=Building%20a%20bespoke%20model)
[\[28\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=To%20address%20the%20aforementioned%20challenges%2C,was%20better%2C%20faster%2C%20and%20cheaper)
[\[29\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=We%20created%20the%20initial%20training,two%20different%20sources%20of%20data)
[\[30\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=,fold%20reduction%20in%20inference%20cost)
[\[31\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=,a%20few%20dollars%2C%20and%20in)
[\[32\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=of%20the%20SaaS%20LLM)
[\[33\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=Model%20selection%20and%20fine)
[\[34\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=The%20first%20step%20was%20to,was%20that%20we%20needed%20to)
[\[35\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=We%20considered%20the%20following%20criteria,for%20model%20selection)
[\[46\]](https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation#:~:text=,we%20did%20a%20lot%20of)
Bespoke LLM for AI-Generated Documentation \| Databricks Blog

<https://www.databricks.com/blog/creating-bespoke-llm-ai-generated-documentation>
